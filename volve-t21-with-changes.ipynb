{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "We are going to use the Volve data.\n",
    "We want to read in the base and monitor surveys, calculate some simple 4D attributes (4D difference and NRMS) and apply a frequency filter to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with importing some basic packages; numpy (as the data will be read into a numpy array), segyio to read the data, matlotlib to plot it and time so we can get some statistics on how long things take\n",
    "\n",
    "***Do we need pandas?  (possible if we are reading the headers)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import segyio\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be a less bonkers path - local to the notebook is probably fine, or with a download link\n",
    "base_segy = 'C:/Users/GDMA/SeisData/Volve/ST0202ZDC12-PZ-PSDM-KIRCH-FULL-T.MIG_FIN.POST_STACK.3D.JS-017534.segy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open('base_sgy') as f:\n",
    "    print(f.tracecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open('base_sgy', ignore_geometry = True) as f:\n",
    "    for text in f.text:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = segyio.open('base_sgy', ignore_geometry = True)\n",
    "ntraces    = len(f.trace)\n",
    "inlines    = []\n",
    "crosslines = []\n",
    "\n",
    "for i in range(nlines):\n",
    "    headeri = f.header[i]\n",
    "    inlines.append(headeri[segyio.su.il])\n",
    "    crosslines.append(headeri[segyio.su.xl])\n",
    "\n",
    "print(f'{ntraces} traces')\n",
    "print(f'first 10 inlines: {inlines[:10]}')\n",
    "print(f'first 10 crosslines: {crosslines[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so what in/crosslines *do* we have?\n",
    "# notice how they taper off\n",
    "plt.plot(inlines, crosslines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i only used to look up the header - can be done directly\n",
    "# this applies to traces too, and, when segyio can figure it out,\n",
    "# inlines and crosslines\n",
    "for header in f.header:\n",
    "    print(header[segyio.su.cdpx, segyio.su.cdpy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segyio\n",
    "\n",
    "JÃ¸rgen to add\n",
    "\n",
    "Get some info about our data\n",
    "- Read the headers?\n",
    "- Plot the x,y locations of the survey?\n",
    "- ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open(base_segy) as segyf:\n",
    "    n_traces = segyf.tracecount\n",
    "    sample_rate = segyio.tools.dt(segyf)/1000\n",
    "    n_samples = segyf.samples.size\n",
    "    n_il = len(segyf.iline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlight problem is that the segy is not a perfect cube (number of inlines * number of xlines = number of traces).<br>\n",
    "There are a number of possible solutions to this. Here use the solution given in one of the segyio example notebooks\n",
    "https://github.com/equinor/segyio-notebooks/blob/master/notebooks/pylops/01_seismic_inversion.ipynb\n",
    "\n",
    "***Need to check/change the naming of the variables since we will be reading 2 volumes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the traces then reshape in numpy\n",
    "t0 = time.time()\n",
    "f = segyio.open(base_segy, ignore_geometry=True)\n",
    "traces = segyio.collect(f.trace)[:]\n",
    "ntraces, nt = traces.shape\n",
    "\n",
    "t = f.samples[:]\n",
    "il = f.attributes(segyio.TraceField.INLINE_3D)[:]\n",
    "xl = f.attributes(segyio.TraceField.CROSSLINE_3D)[:]\n",
    "\n",
    "## Define regular IL and XL axes\n",
    "\n",
    "il_unique = np.unique(il)\n",
    "xl_unique = np.unique(xl)\n",
    "\n",
    "il_min, il_max = min(il_unique), max(il_unique)\n",
    "xl_min, xl_max = min(xl_unique), max(xl_unique)\n",
    "\n",
    "# Get line increment\n",
    "dt = t[1] - t[0]\n",
    "dil = min(np.unique(np.diff(il_unique)))\n",
    "dxl = min(np.unique(np.diff(xl_unique)))\n",
    "\n",
    "# Create grid and get number of inlines & xlines\n",
    "ilines = np.arange(il_min, il_max + dil, dil)\n",
    "xlines = np.arange(xl_min, xl_max + dxl, dxl)\n",
    "nil, nxl = ilines.size, xlines.size\n",
    "\n",
    "ilgrid, xlgrid = np.meshgrid(np.arange(nil),\n",
    "                             np.arange(nxl),\n",
    "                             indexing='ij')\n",
    "\n",
    "# Look-up table\n",
    "traces_indeces = np.full((nil, nxl), np.nan)\n",
    "iils = (il - il_min) // dil\n",
    "ixls = (xl - xl_min) // dxl\n",
    "traces_indeces[iils, ixls] = np.arange(ntraces)\n",
    "traces_available = np.logical_not(np.isnan(traces_indeces))\n",
    "\n",
    "# Reorganize traces in regular grid\n",
    "d = np.zeros((nil, nxl, nt))\n",
    "d[ilgrid.ravel()[traces_available.ravel()],\n",
    "  xlgrid.ravel()[traces_available.ravel()]] = traces\n",
    "# Return the time (in seconds to do this)\n",
    "sgy_r_time = time.time() - t0\n",
    "print(f'segy file with {ntraces} traces ({nil} inlines, {nxl} xlines) indexed and read in {sgy_r_time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the outputs <br>\n",
    "Data is in a 3D numpy array and our inline, crossline and twt are also in separate numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "Now we've read it, let's look at a single line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "imgplot = plt.imshow(d[nil//2,:,:], cmap='gray', aspect='auto', vmin=-5, vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look right - we need to consider the origin and how the data is read.\n",
    "Also add the correct labelling on the axis rather than simply the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correctly\n",
    "# Line\n",
    "extent = [xlines[0],xlines[-1],t[-1],t[0]]\n",
    "imgplot = plt.imshow(d[nil//2,:,:].T, cmap='gray', aspect='auto', vmin=-5, vmax=5, extent=extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-Slice\n",
    "imgplot = plt.imshow(d[:,:,575], cmap='gray', origin='lower', aspect='auto', vmin=-5, vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive plotting\n",
    "\n",
    "Ideally we would like to be scan through some lines.\n",
    "Import some new plotting packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we need these two?\n",
    "#import holoviews as hv\n",
    "#from holoviews import opts\n",
    "# Definitely need these\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import panel as pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inl(inl):\n",
    "    idx = inl - ilines[0]\n",
    "    da = xr.DataArray(d[idx,:,:].T)    \n",
    "    p = da.hvplot.image(clim=(-5, 5), cmap='gray', flip_yaxis=True) \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_slice = pn.interact(plot_inl, inl=ilines)\n",
    "il_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xarray ?\n",
    "\n",
    "Plot above again has no useful axis info <br>\n",
    "Hvplot uses xarray - explain a bit more and put base into an xarray with coordinates - reference back to segysak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Data Array\n",
    "da = xr.DataArray(data=d,\n",
    "                  dims=['il','xl','twt'],\n",
    "                  coords={'il': ilines,\n",
    "                          'xl': xlines,\n",
    "                          'twt': t})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor survey Using seismic-zfp\n",
    "\n",
    "Now we've read and reviewed one vintage, let's read the second\n",
    "\n",
    "Another option to get around the irregular geometry would be to use segysak (ref Tony's tutorial).  Here we'll use a third option and convert the segy file into another format that automatically pads the data.  We will use seismic-zfp which forms a compressed format.  We won't go into detail on this format but more information can be found .... (add links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismic_zfp\n",
    "from seismic_zfp.conversion import SegyConverter, SgzReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to convert the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_segy = 'C:/Users/GDMA/SeisData/Volve/ST10010ZDC12-PZ-PSDM-KIRCH-FULL-T.MIG_FIN.POST_STACK.3D.JS-017534.segy'\n",
    "monitor_sgz = 'C:/Users/gdma/git/volve/data/ST10010_4D_Monitor.sgz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgz_t0 = time.time()\n",
    "with SegyConverter(monitor_segy) as converter:\n",
    "    # Create a \"standard\" SGZ file with 8:1 compression, using in-memory method\n",
    "    converter.run(monitor_sgz, bits_per_voxel=4)\n",
    "sgz_elapse = time.time() - sgz_t0\n",
    "print(f'Converted to sgz in {sgz_elapse} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's converted we can read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cube from zgy\n",
    "t0 = time.time()\n",
    "with SgzReader(monitor_sgz) as reader:\n",
    "    n_traces_m = reader.tracecount\n",
    "    n_il_m = reader.n_ilines\n",
    "    n_xl_m = reader.n_xlines\n",
    "    num_samples_m = reader.n_samples\n",
    "    ilines_m = reader.ilines\n",
    "    xlines_m = reader.xlines\n",
    "    data_m = reader.read_volume()\n",
    "zgy_r_time = time.time() - t0\n",
    "print(f'sgz file with {n_traces_m} traces ({n_il_m} inlines, {n_xl_m} xlines) read in {zgy_r_time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment on run times - overhead of conversion v speed of reading, also comment on compression*\n",
    "\n",
    "Now we've read the monitor survey, let's check they are both the same size and have the same inline, crossline range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of arrays\n",
    "data_m.shape\n",
    "d.shape\n",
    "# Line ranges\n",
    "ilines.min()\n",
    "ilines.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a slice as a quick qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add monitor to xarray\n",
    "# Create a dataset\n",
    "volve_ds = da.to_dataset(name='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the monitor survey\n",
    "monitor = xr.DataArray(data_m)\n",
    "volve_ds['monitor'] = (['il','xl','twt'],monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D Analysis\n",
    "Now we have the 2 volumes we can calculate some simple 4D attributes\n",
    "- Calculate the 4D difference \n",
    "- Calculate the NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency spectra and filtering\n",
    "- Look at the frequency spectra\n",
    "- Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq spectra - make this a function as we'll use it again\n",
    "S = np.mean(np.abs(np.fft.fft(d[:, :, 500:750], axis=-1)), axis=(0, 1))\n",
    "freq = np.fft.fftfreq(len(S), d=0.004)\n",
    "f, amp = freq[:S.size//2], np.abs(S[:S.size//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f, amp, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowpass filter\n",
    "# This is using filtfilt - better to use sosfiltfilt\n",
    "fs = 1/0.004\n",
    "nyq = fs / 2\n",
    "cutoff = 0.25\n",
    "b, a = signal.butter(5, cutoff, btype='lowpass')\n",
    "d_filt = signal.filtfilt(b, a, d, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq spectra again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot with before, after and difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the monitor and calc new difference - depends on time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
